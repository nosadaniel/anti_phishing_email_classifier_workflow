{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nosadaniel/anti_phishing_email_classifier_workflow/blob/main/prepare_training_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrsOiEzXp9ap",
        "outputId": "1d83717d-6fe5-479a-dc9f-7fcbc5ad7274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install jupyter and it dependencies\n",
        "%pip install -q jupyterlab ipywidgets notebook tqdm\n",
        "\n",
        "# Install core LangChain/LangGraph/LangSmith, LLM support, and utilities\n",
        "%pip install -q langgraph langchain langsmith langchain_core langchain_google_genai langchain_community langchain_ollama langchain_mistralai\n",
        "\n",
        "# Install data analysis and visualization libraries\n",
        "%pip install -q matplotlib seaborn plotly scikit-learn pandas numpy\n",
        "\n",
        "# # Install some additional libraries for data processing and visualization\n",
        "# %pip install requests graphviz pygraphviz\n",
        "\n",
        "# instal datasets\n",
        "%pip install -q datasets\n",
        "\n",
        "#install the URl checking tool\n",
        "%pip install -q sec-mcp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update sec-mcp blacklist database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYoY7hPzmGU4",
        "outputId": "e428a4f5-a922-42c5-ac4e-a81ceaad2082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Blacklist update triggered.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-24 22:32:42,285 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for OpenPhish: [('https://bdoonline.faqs-recommended.workers.dev/bdo-form/aMy2Vl38cskcfBTJD1h0RLJkWQaEQdyATS6q1t2HOT', None, '2025-07-24 22:32:42', 8, 'OpenPhish'), ('http://www.3656qqq.com/', None, '2025-07-24 22:32:42', 8, 'OpenPhish'), ('https://prouttonuseipeu.vercel.app/hiwecroutatro/hiwecrouta.html', None, '2025-07-24 22:32:42', 8, 'OpenPhish'), ('http://ee-payment-help.firebaseapp.com/', None, '2025-07-24 22:32:42', 8, 'OpenPhish'), ('https://form.jotform.com/252042896623056', None, '2025-07-24 22:32:42', 8, 'OpenPhish')]\n",
            "2025-07-24 22:32:42,550 - sec_mcp.update_blacklist - INFO - Updated OpenPhish: 167 URLs, 129 domains, 0 IPs.\n",
            "2025-07-24 22:32:44,400 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for URLhaus: [('https://files.catbox.moe/yl839e.dll', None, '2025-07-24 22:32:42', 8, 'URLhaus'), ('https://files.catbox.moe/o7aur7.txt', None, '2025-07-24 22:32:42', 8, 'URLhaus'), ('https://files.catbox.moe/jpjs0n.dll', None, '2025-07-24 22:32:42', 8, 'URLhaus'), ('https://eveloungeyyc.com/lal1.php', None, '2025-07-24 22:32:42', 8, 'URLhaus'), ('https://eveloungeyyc.com/bezs.zip', None, '2025-07-24 22:32:42', 8, 'URLhaus')]\n",
            "2025-07-24 22:32:57,260 - sec_mcp.update_blacklist - INFO - Updated URLhaus: 14465 URLs, 661 domains, 1 IPs.\n",
            "2025-07-24 22:32:57,267 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for SpamhausDROP: [(None, '1.10.16.0/20', '2025-07-24 22:32:57', 8, 'SpamhausDROP'), (None, '1.19.0.0/16', '2025-07-24 22:32:57', 8, 'SpamhausDROP'), (None, '1.32.128.0/18', '2025-07-24 22:32:57', 8, 'SpamhausDROP'), (None, '2.56.192.0/22', '2025-07-24 22:32:57', 8, 'SpamhausDROP'), (None, '2.57.122.0/24', '2025-07-24 22:32:57', 8, 'SpamhausDROP')]\n",
            "2025-07-24 22:32:58,456 - sec_mcp.update_blacklist - INFO - Updated SpamhausDROP: 0 URLs, 0 domains, 1558 IPs.\n",
            "2025-07-24 22:32:58,465 - sec_mcp.update_blacklist - INFO - CINSSCORE first 5 parsed entries: [{'ip': '1.12.246.6', 'date': '2025-07-24 22:32:58', 'score': 8}, {'ip': '1.15.118.23', 'date': '2025-07-24 22:32:58', 'score': 8}, {'ip': '1.172.168.41', 'date': '2025-07-24 22:32:58', 'score': 8}, {'ip': '1.178.215.66', 'date': '2025-07-24 22:32:58', 'score': 8}, {'ip': '1.20.102.56', 'date': '2025-07-24 22:32:58', 'score': 8}]\n",
            "2025-07-24 22:32:58,466 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for CINSSCORE: [(None, '1.12.246.6', '2025-07-24 22:32:58', 8, 'CINSSCORE'), (None, '1.15.118.23', '2025-07-24 22:32:58', 8, 'CINSSCORE'), (None, '1.172.168.41', '2025-07-24 22:32:58', 8, 'CINSSCORE'), (None, '1.178.215.66', '2025-07-24 22:32:58', 8, 'CINSSCORE'), (None, '1.20.102.56', '2025-07-24 22:32:58', 8, 'CINSSCORE')]\n",
            "2025-07-24 22:33:09,896 - sec_mcp.update_blacklist - INFO - Updated CINSSCORE: 0 URLs, 0 domains, 15000 IPs.\n",
            "2025-07-24 22:33:09,899 - sec_mcp.update_blacklist - INFO - EmergingThreats first 5 parsed entries: [{'ip': '101.43.12.185', 'url': None, 'date': '2025-07-24 22:33:09', 'score': 8}, {'ip': '101.78.203.148', 'url': None, 'date': '2025-07-24 22:33:09', 'score': 8}, {'ip': '101.91.208.44', 'url': None, 'date': '2025-07-24 22:33:09', 'score': 8}, {'ip': '102.223.208.49', 'url': None, 'date': '2025-07-24 22:33:09', 'score': 8}, {'ip': '103.143.11.139', 'url': None, 'date': '2025-07-24 22:33:09', 'score': 8}]\n",
            "2025-07-24 22:33:09,899 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for EmergingThreats: [(None, '101.43.12.185', '2025-07-24 22:33:09', 8, 'EmergingThreats'), (None, '101.78.203.148', '2025-07-24 22:33:09', 8, 'EmergingThreats'), (None, '101.91.208.44', '2025-07-24 22:33:09', 8, 'EmergingThreats'), (None, '102.223.208.49', '2025-07-24 22:33:09', 8, 'EmergingThreats'), (None, '103.143.11.139', '2025-07-24 22:33:09', 8, 'EmergingThreats')]\n",
            "2025-07-24 22:33:10,207 - sec_mcp.update_blacklist - INFO - Updated EmergingThreats: 0 URLs, 0 domains, 387 IPs.\n",
            "2025-07-24 22:33:10,207 - sec_mcp.update_blacklist - WARNING - No valid entries found for FeodoTracker during update.\n",
            "2025-07-24 22:33:10,207 - sec_mcp.update_blacklist - INFO - Updated FeodoTracker: 0 URLs, 0 domains, 0 IPs.\n",
            "2025-07-24 22:33:10,284 - sec_mcp.update_blacklist - INFO - BlocklistDE first 5 parsed entries: [{'ip': '1.12.48.131', 'url': None, 'date': '2025-07-24 22:33:10', 'score': 8}, {'ip': '1.15.148.9', 'url': None, 'date': '2025-07-24 22:33:10', 'score': 8}, {'ip': '1.15.80.32', 'url': None, 'date': '2025-07-24 22:33:10', 'score': 8}, {'ip': '1.180.230.98', 'url': None, 'date': '2025-07-24 22:33:10', 'score': 8}, {'ip': '1.180.97.138', 'url': None, 'date': '2025-07-24 22:33:10', 'score': 8}]\n",
            "2025-07-24 22:33:10,288 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for BlocklistDE: [(None, '1.12.48.131', '2025-07-24 22:33:10', 8, 'BlocklistDE'), (None, '1.15.148.9', '2025-07-24 22:33:10', 8, 'BlocklistDE'), (None, '1.15.80.32', '2025-07-24 22:33:10', 8, 'BlocklistDE'), (None, '1.180.230.98', '2025-07-24 22:33:10', 8, 'BlocklistDE'), (None, '1.180.97.138', '2025-07-24 22:33:10', 8, 'BlocklistDE')]\n",
            "2025-07-24 22:33:26,119 - sec_mcp.update_blacklist - INFO - Updated BlocklistDE: 0 URLs, 0 domains, 20559 IPs.\n",
            "2025-07-24 22:33:26,273 - httpx - INFO - HTTP Request: GET https://data.phishtank.com/data/online-valid.csv \"HTTP/1.1 302 Found\"\n",
            "2025-07-24 22:33:26,370 - httpx - INFO - HTTP Request: GET https://cdn.phishtank.com/datadumps/verified_online.csv?Expires=1753389183&Signature=M7UmOKo7ebIhyg0zHBD3ISV0yf2m5lGmyEEDVV7jAzubIe3jqNDrlvEDjHL1tQC6R0BdYbp7LJRCtLZ55ZhxzewYXGMF4SBy7kCdtAo-ICUMoobjjNG7JuByAwurW1T16Rd3hGJFdMlD~uHKSphRhRKAlKUc25fpX6tmuhTRo7qnUxT9B3XFE5XRHk9UxhK29UlzrmYZpEFWVrj54hxEtBzxvuUHDb52pwXZralLFP520ny1U11rd-9hAiLsTubeuZzav39Dnz2DzYzVEWye8X1zfDUe3TVGOK0V75SAM2XFNSVpwW6xdO7K6SY3VLuvG0WEK1g9tk-3Ah-FOhZCKA__&Key-Pair-Id=APKAILB45UG3RB4CSOJA \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 22:33:26,472 - httpx - INFO - HTTP Request: GET https://phishstats.info/phish_score.csv \"HTTP/1.1 404 Not Found\"\n",
            "2025-07-24 22:33:26,472 - sec_mcp.update_blacklist - ERROR - Failed to update PhishStats: Client error '404 Not Found' for url 'https://phishstats.info/phish_score.csv'\n",
            "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\n",
            "2025-07-24 22:33:26,497 - httpx - INFO - HTTP Request: GET https://www.dshield.org/block.txt \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 22:33:26,500 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for Dshield: [(None, '79.124.62.0', '2025-07-24 22:33:26', 8, 'Dshield'), (None, '167.94.138.0', '2025-07-24 22:33:26', 8, 'Dshield'), (None, '93.152.230.0', '2025-07-24 22:33:26', 8, 'Dshield'), (None, '185.242.226.0', '2025-07-24 22:33:26', 8, 'Dshield'), (None, '87.121.84.0', '2025-07-24 22:33:26', 8, 'Dshield')]\n",
            "2025-07-24 22:33:26,521 - sec_mcp.update_blacklist - INFO - Updated Dshield: 0 URLs, 0 domains, 20 IPs.\n",
            "2025-07-24 22:33:29,078 - sec_mcp.update_blacklist - INFO - First 5 parsed entries for PhishTank: [('https://allegrolokalnie.pl-kategorie78172318245126.shop/?id=Dacg4O5AKhnIFdgDkcjM08f3ggadbg&amp;amp;fbclid=IwY2xjawLvYTtleHRuA2FlbQIxMQABHvA1SuDlTYpA8dvbE4JTEeCV_WUbtc7Ly7eqY8Fi57kt7huYLulbbK6ZB8XY_aem_Gj61IzzjJ7VlFcHGk_d2cg&amp;amp;sfnsn=wa', None, '2025-07-24 19:46:30', 8, 'PhishTank'), ('https://atlas-morocco-tours.com/wp-admin/mycs/', None, '2025-07-24 19:38:03', 8, 'PhishTank'), ('https://mez.ink/attservicehomeredirect', None, '2025-07-24 19:29:54', 8, 'PhishTank'), ('https://allegrolokalnie.pl-oferta573925.sbs/?id=h99NdihcDOIGC8mmhia3E09mkbajaD', None, '2025-07-24 19:23:18', 8, 'PhishTank'), ('http://103.29.68.53:8200/csh02.html', None, '2025-07-24 19:21:35', 8, 'PhishTank')]\n",
            "2025-07-24 22:34:14,529 - sec_mcp.update_blacklist - INFO - Updated PhishTank: 33547 URLs, 18426 domains, 0 IPs.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entries: 130610\n",
            "Last update: 0001-01-01 00:00:00\n",
            "Active sources:\n",
            "  - BlocklistDE: 32766 entries\n",
            "  - OpenPhish: 1154 entries\n",
            "  - CINSSCORE: 24229 entries\n",
            "  - EmergingThreats: 291 entries\n",
            "  - Dshield: 31 entries\n",
            "  - URLhaus: 16704 entries\n",
            "  - SpamhausDROP: 1581 entries\n",
            "  - PhishTank: 53854 entries\n",
            "\n",
            "Per-source breakdown:\n",
            "Source                Domains       URLs        IPs\n",
            "--------------------------------------------------\n",
            "BlocklistDE                 0          0      32766\n",
            "CINSSCORE                   0          0      24229\n",
            "Dshield                     0          0         31\n",
            "EmergingThreats             0          0        291\n",
            "OpenPhish                 468        686          0\n",
            "PhishTank               18919      34935          0\n",
            "SpamhausDROP                0          0       1581\n",
            "URLhaus                   663      16040          1\n",
            "\n",
            "Server status: Running (STDIO)\n"
          ]
        }
      ],
      "source": [
        "# update the sec-mcp blacklist database\n",
        "!sec-mcp update\n",
        "\n",
        "#check sec-mcp status(optional)\n",
        "!sec-mcp status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUBOuUHPzCrb"
      },
      "source": [
        "## Load enviroment variables from .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8crHJ2gGsuc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".env file found => d:\\developer\\montimage\\anti_phishing_email_classifier_workflow\\.env\n",
            ".env file loaded: True\n",
            "ollama\n",
            "llama3.2:3b\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv  \n",
        "\n",
        "dotenv_path = os.path.join(os.getcwd(), '.env')\n",
        "if os.path.exists(dotenv_path):\n",
        "    print(f\".env file found => {dotenv_path}\")\n",
        "    has_loaded = load_dotenv(dotenv_path)\n",
        "    print(f\".env file loaded: {has_loaded}\")\n",
        "else:\n",
        "    print(\".env file not found\")\n",
        "    exit()\n",
        "\n",
        "# Load environment variables\n",
        "google_api_key = os.environ.get('GOOGLE_API_KEY')\n",
        "langsmith_endpoint = os.environ.get('LANGSMITH_ENDPOINT')\n",
        "langsmith_api_key = os.environ.get('LANGSMITH_API_KEY')\n",
        "langsmith_tracing = os.environ.get('LANGSMITH_TRACING')\n",
        "langsmith_project = os.environ.get('LANGSMITH_PROJECT')\n",
        "mistral_api_key = os.environ.get('MISTRAL_API_KEY')\n",
        "llm_model = os.environ.get('LLM_MODEL')\n",
        "llm_provider = os.environ.get('LLM_PROVIDER')\n",
        "\n",
        "\n",
        "print(llm_provider)\n",
        "print(llm_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get LLM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGCy_3wZ1a5F",
        "outputId": "902f1070-9a24-44fc-9de1-b69d0a50ae10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM: model='llama3.2:3b' temperature=0.0 base_url='http://127.0.0.1:11434'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=3640eeef-0c84-40af-950a-b412468eb68f,id=3640eeef-0c84-40af-950a-b412468eb68f\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Je aime programmer.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=3640eeef-0c84-40af-950a-b412468eb68f,id=3640eeef-0c84-40af-950a-b412468eb68f\n",
            "2025-07-24 22:34:25,844 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=c308bcb9-7172-49a8-a8be-3cb8593fe045; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=bc614193-690b-4bfe-87ff-d313d6a39820\n",
            "2025-07-24 22:34:26,488 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=41243880-8b92-4154-94f1-7bfe91899a46; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=cf926cb3-0b12-4d50-b3b4-4ea7e81d5ab8; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=d94a7b22-1f9c-41cc-92e2-d59f8b0e992f; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=3b19dfd1-2fa0-4da7-bb2e-694d786c9850; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=54614d14-ffb7-4766-9b2f-4494c13c0354; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=54614d14-ffb7-4766-9b2f-4494c13c0354; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=1eddd24d-cc71-4b42-bf93-61844f927747\n",
            "2025-07-24 22:34:29,360 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=1eddd24d-cc71-4b42-bf93-61844f927747; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=3b19dfd1-2fa0-4da7-bb2e-694d786c9850; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=d94a7b22-1f9c-41cc-92e2-d59f8b0e992f; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=274dfcb4-7666-47be-bfcc-080705e62375; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=274dfcb4-7666-47be-bfcc-080705e62375; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=cf926cb3-0b12-4d50-b3b4-4ea7e81d5ab8; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=93d0ea39-9f6b-4572-af92-16980baf0d6b; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=64369a6b-8792-4ee1-887e-1f3bb01d07c8; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=64369a6b-8792-4ee1-887e-1f3bb01d07c8; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=93d0ea39-9f6b-4572-af92-16980baf0d6b; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=274c8b4f-6f51-4284-8806-796be646e929; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=45e602c8-7993-4b69-967f-c8b2e99115b4; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=ae7d4cbf-4423-40ff-baf9-13bb2ac73971; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=b7625ddc-debe-4bc1-a006-bd99fd7e2093; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=b7625ddc-debe-4bc1-a006-bd99fd7e2093; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=cc4caeee-f58a-415c-a5ae-4c00cb06beaa\n",
            "2025-07-24 22:34:35,923 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=cc4caeee-f58a-415c-a5ae-4c00cb06beaa; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=ae7d4cbf-4423-40ff-baf9-13bb2ac73971; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=45e602c8-7993-4b69-967f-c8b2e99115b4; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=f0ad155c-1f79-47ad-8f2e-e369881ac733; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=f0ad155c-1f79-47ad-8f2e-e369881ac733; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=274c8b4f-6f51-4284-8806-796be646e929; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=1a0ae937-090b-4f08-9648-3c69eea9e99d; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=df87145f-55a6-43bb-a24b-9c7afae9ad73; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=e88aec74-be3c-4158-bbff-1bdd05a4bf29; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=9de5865f-ff48-4df5-bc38-69caaabe0d3d\n",
            "2025-07-24 22:34:38,887 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=9de5865f-ff48-4df5-bc38-69caaabe0d3d; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=a412074e-af2b-44b7-bb38-1fde4d87e667; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=a412074e-af2b-44b7-bb38-1fde4d87e667; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=e88aec74-be3c-4158-bbff-1bdd05a4bf29; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=df87145f-55a6-43bb-a24b-9c7afae9ad73; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=1a0ae937-090b-4f08-9648-3c69eea9e99d; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=41243880-8b92-4154-94f1-7bfe91899a46; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=bc614193-690b-4bfe-87ff-d313d6a39820; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=5212c271-9bcd-4fdf-9d53-c5dd35b29132; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=5212c271-9bcd-4fdf-9d53-c5dd35b29132; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=1d5144d5-b776-44ab-8c61-09b9fda1839b; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=1d5144d5-b776-44ab-8c61-09b9fda1839b; trace=c308bcb9-7172-49a8-a8be-3cb8593fe045,id=c308bcb9-7172-49a8-a8be-3cb8593fe045\n",
            "2025-07-24 23:21:45,039 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=fc7ead31-8995-4b7f-b84e-925c7879875c\n",
            "2025-07-24 23:21:45,686 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=ad18814a-e7fd-4361-b2ec-2e8b31ffce12; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=0a4c493e-f7e3-47dc-a2af-a1d633d9d433; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=3d9a28c4-d91d-4219-b0ad-04b6d2bcf04c; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=d43c0f41-dc4e-423b-964e-bb6d78d8cf76; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=08b896eb-eacf-44aa-b1a8-d6679ba17895; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=08b896eb-eacf-44aa-b1a8-d6679ba17895; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=e8e92e67-b96f-4469-9093-5128958e43b3; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=e8e92e67-b96f-4469-9093-5128958e43b3; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=d43c0f41-dc4e-423b-964e-bb6d78d8cf76; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=3d9a28c4-d91d-4219-b0ad-04b6d2bcf04c; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=f16c0a85-a40b-4ee6-991a-71bf93bd9734; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=f16c0a85-a40b-4ee6-991a-71bf93bd9734; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=0a4c493e-f7e3-47dc-a2af-a1d633d9d433; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=42c87303-f88b-4bee-b226-22f7d9b663f9; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=b80d2ed3-b409-4bf7-bc90-ee8d516a38fc; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=b80d2ed3-b409-4bf7-bc90-ee8d516a38fc; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=42c87303-f88b-4bee-b226-22f7d9b663f9; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=3f61dbb1-935e-44c0-b9f9-d588af5dd2f5; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=4139a02a-7afe-4eaf-8ae2-6d3ea83fe846; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=23a90173-afef-452a-8d33-5af562cc587e; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=8b920d3f-e5ae-46f1-a949-b7f23f8891f9; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=8b920d3f-e5ae-46f1-a949-b7f23f8891f9; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=3ba70dc5-281b-4c67-b739-696e45b39169; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=3ba70dc5-281b-4c67-b739-696e45b39169; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=23a90173-afef-452a-8d33-5af562cc587e; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=4139a02a-7afe-4eaf-8ae2-6d3ea83fe846; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=efb0e07d-d211-4038-838d-6ca1a6a67a10; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=efb0e07d-d211-4038-838d-6ca1a6a67a10; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=3f61dbb1-935e-44c0-b9f9-d588af5dd2f5; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=02930322-9278-433a-868b-2dac0a44893d; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=912145f5-f2b1-486f-a510-4e65b50db8df; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=9c5cb634-37c2-46e1-8e7a-6761de37a294; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=337ed669-eb01-4d1e-85ba-1806156a356e; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=337ed669-eb01-4d1e-85ba-1806156a356e; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=752a0aee-16d4-4185-adb8-849b70ef0ff3; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=752a0aee-16d4-4185-adb8-849b70ef0ff3; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=9c5cb634-37c2-46e1-8e7a-6761de37a294; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=912145f5-f2b1-486f-a510-4e65b50db8df; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=02930322-9278-433a-868b-2dac0a44893d; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=ad18814a-e7fd-4361-b2ec-2e8b31ffce12; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=fc7ead31-8995-4b7f-b84e-925c7879875c; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=fc8b109f-56dc-46d2-a133-b3a7ac9df884; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=fc8b109f-56dc-46d2-a133-b3a7ac9df884; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=5fd866b5-8bda-437b-9a72-33452541011a; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=5fd866b5-8bda-437b-9a72-33452541011a; trace=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d,id=1f1ed301-5579-42c6-9ef3-02fe08e3bc9d; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=7a8bff2d-f84e-4db8-85e8-728b1d0570b5; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=b768dd46-f4ee-46ed-8ce3-6d1f103c897b; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=16871395-635b-47cd-92be-64cf13d6574b; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=123f9bd9-29cf-49a7-97b0-3debc1e89522; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=3dd9f7e7-576f-4b53-b5b9-9a92156b424c; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=6c957754-0794-47c5-9cb1-423bdfb440dd; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=acec0c17-8740-4eaa-8e0d-c2ba03c1c571; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=acec0c17-8740-4eaa-8e0d-c2ba03c1c571; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=92dfec06-2756-43d6-aa38-ac647e71761d; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=92dfec06-2756-43d6-aa38-ac647e71761d; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=6c957754-0794-47c5-9cb1-423bdfb440dd; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=3dd9f7e7-576f-4b53-b5b9-9a92156b424c; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=ba557f35-171f-426a-a1dc-35836b486997; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=ba557f35-171f-426a-a1dc-35836b486997; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=123f9bd9-29cf-49a7-97b0-3debc1e89522; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=7181d3d0-8b85-4c98-b1e4-9c9d9fefecbd; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=32a270ab-126b-4921-be25-098b743c2c04; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=32a270ab-126b-4921-be25-098b743c2c04; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=7181d3d0-8b85-4c98-b1e4-9c9d9fefecbd; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=b0daa164-63c3-4768-955d-e0b0081d6866; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=84f13644-16be-44d0-b617-9afbdad41374; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=efa559d7-ad5c-4501-8b79-aa22c51803d8; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=3da669a8-ce45-4449-98b1-801ee6e7bca0; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=3da669a8-ce45-4449-98b1-801ee6e7bca0; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=561bd3ca-048e-4a6a-9a24-d2d4b417f97f\n",
            "2025-07-24 23:21:50,651 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=561bd3ca-048e-4a6a-9a24-d2d4b417f97f; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=efa559d7-ad5c-4501-8b79-aa22c51803d8; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=84f13644-16be-44d0-b617-9afbdad41374; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=7cbc183a-fa18-47cb-a3b0-6708ec6e65ee; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=7cbc183a-fa18-47cb-a3b0-6708ec6e65ee; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=b0daa164-63c3-4768-955d-e0b0081d6866; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=ba70c67a-bb27-460c-a106-9dfd69230ba3; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=330fb888-9e92-489e-9ea9-70bd13917b2e; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=d9e6b06d-1624-462f-866b-7ae9d712bd07; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=bd103c87-e786-425c-88ee-da3c2fb7e112\n",
            "2025-07-24 23:21:53,881 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=bd103c87-e786-425c-88ee-da3c2fb7e112; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=95f64624-5028-42ed-ab68-3f14e107e945; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=95f64624-5028-42ed-ab68-3f14e107e945; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=d9e6b06d-1624-462f-866b-7ae9d712bd07; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=330fb888-9e92-489e-9ea9-70bd13917b2e; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=ba70c67a-bb27-460c-a106-9dfd69230ba3; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=16871395-635b-47cd-92be-64cf13d6574b; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=b768dd46-f4ee-46ed-8ce3-6d1f103c897b; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=fcc0bee8-ce0c-4143-8f44-7914f198f863; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=fcc0bee8-ce0c-4143-8f44-7914f198f863; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=ccce14b2-a1d1-4d2e-a21d-553a09d429da; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=ccce14b2-a1d1-4d2e-a21d-553a09d429da; trace=7a8bff2d-f84e-4db8-85e8-728b1d0570b5,id=7a8bff2d-f84e-4db8-85e8-728b1d0570b5; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=8878391e-b47b-4c14-8458-89c3f843f415; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=07c348a8-52df-4097-9fc2-3df3ac30188c\n",
            "2025-07-24 23:21:54,582 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c1ac06fa-7a67-478b-99e4-1bf5aedae964; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=24e2bfa8-87e9-4df5-a36f-46f7a3fb3681; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=14d3774f-06b4-491d-9fcf-9b6766ed9678; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=04f10c37-6a1d-4071-bedc-1f85209e49cb; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=cf8882b4-7aa4-4cc0-a10f-11391d05a7b5; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=cf8882b4-7aa4-4cc0-a10f-11391d05a7b5; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c0e96c1b-f8ac-4468-a897-6256a5e3f2a8\n",
            "2025-07-24 23:22:02,144 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c0e96c1b-f8ac-4468-a897-6256a5e3f2a8; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=04f10c37-6a1d-4071-bedc-1f85209e49cb; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=14d3774f-06b4-491d-9fcf-9b6766ed9678; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=9fa8c636-4e31-4a87-b4ac-930434f2cf8e; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=9fa8c636-4e31-4a87-b4ac-930434f2cf8e; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=24e2bfa8-87e9-4df5-a36f-46f7a3fb3681; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=5dee122a-fea5-4236-99b7-af83b77ad757; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c95b917b-ae65-4317-af7b-8359e95372b9; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c95b917b-ae65-4317-af7b-8359e95372b9; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=5dee122a-fea5-4236-99b7-af83b77ad757; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=77d7b47b-cba4-49a5-b3b8-92bb4e8bc9d2; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c2638ea0-42f8-4543-a44a-cd227882526e; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=b24bb422-e856-448a-8bc3-ad97567230f6; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=f0fdb5da-856c-4efc-b691-be773019d78f; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=f0fdb5da-856c-4efc-b691-be773019d78f; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=9270141c-0ada-4894-9ca7-6fa7a87416b7\n",
            "2025-07-24 23:22:17,324 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=8878391e-b47b-4c14-8458-89c3f843f415,id=9270141c-0ada-4894-9ca7-6fa7a87416b7; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=b24bb422-e856-448a-8bc3-ad97567230f6; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c2638ea0-42f8-4543-a44a-cd227882526e; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=219088d9-fcd1-466c-aef0-ce4e1a11223f; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=219088d9-fcd1-466c-aef0-ce4e1a11223f; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=77d7b47b-cba4-49a5-b3b8-92bb4e8bc9d2; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=0c93401a-3219-48c1-a07b-db4363597dd9; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=5012f1b0-e97b-414a-980e-ffca27257075; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=b0fb473b-4bd7-45e6-977d-2ae5fb69acbc; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=fc91c059-3021-47d1-9222-3a1ead6026ef\n",
            "2025-07-24 23:22:26,286 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=8878391e-b47b-4c14-8458-89c3f843f415,id=fc91c059-3021-47d1-9222-3a1ead6026ef; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=fb44c822-7686-4236-8844-2d3ede9bc850; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=fb44c822-7686-4236-8844-2d3ede9bc850; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=b0fb473b-4bd7-45e6-977d-2ae5fb69acbc; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=5012f1b0-e97b-414a-980e-ffca27257075; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=0c93401a-3219-48c1-a07b-db4363597dd9; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=c1ac06fa-7a67-478b-99e4-1bf5aedae964; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=07c348a8-52df-4097-9fc2-3df3ac30188c; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=f2ff68c2-d470-47df-91a0-a9fc38d73889; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=f2ff68c2-d470-47df-91a0-a9fc38d73889; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=51c1f22f-1bb3-4f48-828f-8ee527bb016a; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=51c1f22f-1bb3-4f48-828f-8ee527bb016a; trace=8878391e-b47b-4c14-8458-89c3f843f415,id=8878391e-b47b-4c14-8458-89c3f843f415; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=29cb8602-8460-45a5-891d-029b8c03bbb6; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=e31538ba-aa38-444a-8908-788e18f08c34\n",
            "2025-07-24 23:22:26,943 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=05cce01c-9ae3-4ae4-a612-faee5555100b; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=bfba73ef-2063-40b0-8f7f-ac0120f09b27; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=8daa00f8-4065-4638-986c-60ba81199d5a; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=c007c8e9-19fb-4d68-91b1-9f4735f85384; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=7ce75542-dc26-4a98-816f-68e10c2cbd80; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=7ce75542-dc26-4a98-816f-68e10c2cbd80; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=f3670686-6eec-4e47-b60c-a0d3d09e3708\n",
            "2025-07-24 23:22:55,723 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=f3670686-6eec-4e47-b60c-a0d3d09e3708; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=c007c8e9-19fb-4d68-91b1-9f4735f85384; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=8daa00f8-4065-4638-986c-60ba81199d5a; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=845191ac-c3ce-4f15-90b1-af6d09ab9374; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=845191ac-c3ce-4f15-90b1-af6d09ab9374; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=bfba73ef-2063-40b0-8f7f-ac0120f09b27; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=6b0ea789-d1ba-4e34-8f2f-84b602a17673; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=e969f055-25ab-4aec-9784-59b13f7b350a; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=c8db2031-0cc3-4a8e-940c-9c7517b22511; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=250a2fca-35ef-4642-be36-c2f946721f0c\n",
            "2025-07-24 23:22:58,679 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=250a2fca-35ef-4642-be36-c2f946721f0c; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=68c4832b-2149-454a-9bc2-af5c73a8ee18; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=68c4832b-2149-454a-9bc2-af5c73a8ee18; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=c8db2031-0cc3-4a8e-940c-9c7517b22511; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=e969f055-25ab-4aec-9784-59b13f7b350a; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=6b0ea789-d1ba-4e34-8f2f-84b602a17673; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=05cce01c-9ae3-4ae4-a612-faee5555100b; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=e31538ba-aa38-444a-8908-788e18f08c34; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=850b15aa-3370-41c8-bc65-b99e0ce6e062; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=850b15aa-3370-41c8-bc65-b99e0ce6e062; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=ae20ad8b-f39d-4d7f-928d-1505467cb0bd; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=ae20ad8b-f39d-4d7f-928d-1505467cb0bd; trace=29cb8602-8460-45a5-891d-029b8c03bbb6,id=29cb8602-8460-45a5-891d-029b8c03bbb6; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=83305686-17d0-42bc-943d-fecbea8337ea; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=490ff4af-09a9-4a96-8378-1bc11a594fb4\n",
            "2025-07-24 23:22:59,352 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=83305686-17d0-42bc-943d-fecbea8337ea,id=045e1034-c3fe-4a7d-991f-b19d50c3ea76; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=940af74c-78d0-4c79-9102-010b9b9c235c; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=c61ccda6-b609-4d27-a44c-b54660be0ead; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=ae7144cd-eac1-4906-889c-e14c59712c46; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=814a2b3a-8760-4c39-a30e-0033885f5921; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=814a2b3a-8760-4c39-a30e-0033885f5921; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=cdb7e577-d4e1-46d9-9274-51e3325bb57a\n",
            "2025-07-24 23:23:03,796 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=83305686-17d0-42bc-943d-fecbea8337ea,id=cdb7e577-d4e1-46d9-9274-51e3325bb57a; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=ae7144cd-eac1-4906-889c-e14c59712c46; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=c61ccda6-b609-4d27-a44c-b54660be0ead; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=223a5526-b3e7-42b2-9df8-b3de0ffcdcdd; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=223a5526-b3e7-42b2-9df8-b3de0ffcdcdd; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=940af74c-78d0-4c79-9102-010b9b9c235c; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=31fc36c7-94fc-4fa7-8c4f-23637d2bf469; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=76bb308d-69ee-4c42-8cf2-a04116b62fd8; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=76bb308d-69ee-4c42-8cf2-a04116b62fd8; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=31fc36c7-94fc-4fa7-8c4f-23637d2bf469; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=b050a540-2a26-4777-b7d1-55cb5eae0342; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=a1984baf-59e4-46b6-8f0b-ccf7b869a704; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=09006338-9128-48b5-9438-636e36044306; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=d706a619-7f17-4b31-9c92-fcc5e321afb0; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=d706a619-7f17-4b31-9c92-fcc5e321afb0; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=5c216334-d924-4e6e-a76b-41868ba6c2c8\n",
            "2025-07-24 23:23:14,801 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=83305686-17d0-42bc-943d-fecbea8337ea,id=5c216334-d924-4e6e-a76b-41868ba6c2c8; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=09006338-9128-48b5-9438-636e36044306; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=a1984baf-59e4-46b6-8f0b-ccf7b869a704; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=3dba8102-15cb-4d35-9f7e-2721768a1148; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=3dba8102-15cb-4d35-9f7e-2721768a1148; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=b050a540-2a26-4777-b7d1-55cb5eae0342; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=e12ae205-70d2-4b10-b20b-557711a39d1a; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=ba3f2f9e-f8bb-48f9-a865-4c494941b99c; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=cea18e3a-679c-498e-bcbf-6b420cbb8a4b; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=661f5852-81f1-482d-9667-c29ccc7f9e99\n",
            "2025-07-24 23:23:19,261 - langsmith.client - WARNING - Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: Monthly unique traces usage limit exceeded\"}\\n')trace=83305686-17d0-42bc-943d-fecbea8337ea,id=661f5852-81f1-482d-9667-c29ccc7f9e99; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=4d5ab5a2-6956-49c4-967d-b719bf6ab1a8; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=4d5ab5a2-6956-49c4-967d-b719bf6ab1a8; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=cea18e3a-679c-498e-bcbf-6b420cbb8a4b; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=ba3f2f9e-f8bb-48f9-a865-4c494941b99c; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=e12ae205-70d2-4b10-b20b-557711a39d1a; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=045e1034-c3fe-4a7d-991f-b19d50c3ea76; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=490ff4af-09a9-4a96-8378-1bc11a594fb4; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=d9f8e29d-5894-471d-baf3-35285f2c38b7; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=d9f8e29d-5894-471d-baf3-35285f2c38b7; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=4802c0ce-476f-4a1b-8633-bebe2338d7e2; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=4802c0ce-476f-4a1b-8633-bebe2338d7e2; trace=83305686-17d0-42bc-943d-fecbea8337ea,id=83305686-17d0-42bc-943d-fecbea8337ea\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "def get_llm():\n",
        "  try:\n",
        "    llm = None\n",
        "    if llm_provider == 'gemini':\n",
        "      llm = ChatGoogleGenerativeAI(\n",
        "        model=llm_model, temperature=0.0)\n",
        "    if llm_provider == \"ollama\":\n",
        "      llm = ChatOllama(\n",
        "        model=llm_model, temperature=0.0, base_url=\"http://127.0.0.1:11434\")\n",
        "    if llm_provider == \"mistral\":\n",
        "      llm = ChatMistralAI(\n",
        "        model=llm_model, temperature=0, max_retries=2)\n",
        "    if llm is None:\n",
        "      raise Exception(\"Invalid LLM provider name\")\n",
        "    return llm\n",
        "  except Exception as e:\n",
        "    print(f\"Error getting LLM: {e}\")\n",
        "    raise e\n",
        "\n",
        "# example\n",
        "llm = get_llm()\n",
        "if llm is not None:\n",
        "  print(f\"LLM: {llm}\")\n",
        "  messages = [\n",
        "                (\"system\", \"Translate the user sentence to French.\"),\n",
        "                (\"human\", \"I love programming.\"),\n",
        "            ]\n",
        "  result = llm.invoke(messages)\n",
        "\n",
        "  print(result.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHHFHBW6wiiF"
      },
      "source": [
        "### load all .csv dataset files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gclvcErEwl7g",
        "outputId": "981da011-4310-4849-8d5a-57c87e24a73d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available dataset: datasets\\CEAS_08.csv\n",
            "Available dataset: datasets\\Nazario.csv\n",
            "Available dataset: datasets\\Nigerian_Fraud.csv\n",
            "Available dataset: datasets\\SpamAssasin.csv\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "#get all available datasets files\n",
        "def get_all_available_dataset_files()->List[str]:\n",
        "  try:\n",
        "    # Define path to the dataset directory\n",
        "    dataset_dir = Path('datasets')\n",
        "    #list available datasets\n",
        "    available_datasets = [file for file in dataset_dir.glob('*.csv')]\n",
        "    return available_datasets\n",
        "  except Exception as e:\n",
        "    print(f\"Error getting available datasets: {e}\")\n",
        "    raise e\n",
        "\n",
        "# usage\n",
        "available_datasets = get_all_available_dataset_files()\n",
        "for dataset in available_datasets:\n",
        "    print(f\"Available dataset: {dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-9MLt1LzJja"
      },
      "source": [
        "### Load  dataset helpers function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "f490a84258294dc4b78a7f9997b9ae85",
            "121ef0adc4944fdcb4cbc4958fa37a74",
            "f9b36947e87e419b80403e8586597fd1",
            "dad3fe94f6fc4f18936231d99fb860a9",
            "00c1ca73f4234ef2930f46988ac489e7",
            "67a2d0c30f81481097771dc46b5b7588",
            "ee28a8c6f7ae4cee9b5b5530b53f0e97",
            "212bf92465314d8599a2c17b974f24ee",
            "71e4a9c13386409ab38423878af4698a",
            "6814cc14c1f44d7eb26ff232559074ec",
            "f5d91e0958da45ecac4f009fe6a24170"
          ]
        },
        "id": "qQ2kvHMy0A3E",
        "outputId": "b75d1eae-0f3b-4257-fde1-d21884b0aaf1"
      },
      "outputs": [],
      "source": [
        "# load dataset into\n",
        "from datasets import load_dataset, DatasetDict, Dataset, IterableDatasetDict, IterableDataset\n",
        "\n",
        "# load each dataset file\n",
        "def load_local_dataset(type, path:str)-> DatasetDict | Dataset | IterableDatasetDict | IterableDataset | None:\n",
        "  try:\n",
        "    dataset = load_dataset(type, data_files=path,split='train')\n",
        "  except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    return None\n",
        "  return dataset\n",
        "\n",
        "\n",
        "# filter each dataset by label\n",
        "def filter_dataset_by_label(dataset, label_value:int=None)-> DatasetDict | Dataset | IterableDatasetDict | IterableDataset:\n",
        "  if label_value is None:\n",
        "    return dataset\n",
        "  else:\n",
        "    data = dataset.filter(lambda x: x['label'] == label_value)\n",
        "    print(f\"Number of {'phishing' if label_value == 1 else 'legitimate'} emails=> {len(data)}\")\n",
        "    return data \n",
        "\n",
        "# limit dataset range\n",
        "def limit_dataset_range(dataset, limit:int=None)-> DatasetDict | Dataset | IterableDatasetDict | IterableDataset:\n",
        "  if limit is None:\n",
        "    return dataset\n",
        "  else:\n",
        "    data = dataset.select(range(limit))\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of legitimate emails=> 17312\n",
            "Number of legitimate emails=> 0\n",
            "Number of legitimate emails=> 0\n",
            "Number of legitimate emails=> 4091\n",
            "Number of phishing emails=> 21842\n",
            "Number of phishing emails=> 1565\n",
            "Number of phishing emails=> 3332\n",
            "Number of phishing emails=> 1718\n",
            "Number of legitimate emails=> 17312\n",
            "Number of legitimate emails=> 0\n",
            "Number of legitimate emails=> 0\n",
            "Number of legitimate emails=> 4091\n",
            "Number of phishing emails=> 21842\n",
            "Number of phishing emails=> 1565\n",
            "Number of phishing emails=> 3332\n",
            "Number of phishing emails=> 1718\n",
            "all_email => [{'data': Dataset({\n",
            "    features: ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls'],\n",
            "    num_rows: 39154\n",
            "}), 'file_name': 'ceas_08.csv', 'label': None, 'total_number': 39154}, {'data': Dataset({\n",
            "    features: ['sender', 'receiver', 'date', 'subject', 'body', 'urls', 'label'],\n",
            "    num_rows: 1565\n",
            "}), 'file_name': 'nazario.csv', 'label': None, 'total_number': 1565}, {'data': Dataset({\n",
            "    features: ['sender', 'receiver', 'date', 'subject', 'body', 'urls', 'label'],\n",
            "    num_rows: 3332\n",
            "}), 'file_name': 'nigerian_fraud.csv', 'label': None, 'total_number': 3332}, {'data': Dataset({\n",
            "    features: ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls'],\n",
            "    num_rows: 5809\n",
            "}), 'file_name': 'spamassasin.csv', 'label': None, 'total_number': 5809}]\n"
          ]
        }
      ],
      "source": [
        "# get phishing and non phishing emails\n",
        "def get_dataset_from_files(limit:int = None, label:int = None):\n",
        "    # all dataset files\n",
        "    all_dataset_files = get_all_available_dataset_files()\n",
        "    dataset_list = []\n",
        "    for file in all_dataset_files:\n",
        "        # load each file dataset\n",
        "        loaded_dataset = load_local_dataset('csv', f\"{file}\")\n",
        "        # filter the loaded dataset by label\n",
        "        filter_dataset = filter_dataset_by_label(loaded_dataset, label)\n",
        "\n",
        "        # limit the range of the dataset\n",
        "        limit_dataset = limit_dataset_range(filter_dataset, limit)\n",
        "\n",
        "        # add to a list\n",
        "        label_text = \"legitimate\" if label==0 else \"phishing\"\n",
        "        dataset_list.append({\"data\":limit_dataset, \"file_name\":file.name.lower(), \"label\": None if label is None else label_text, \"total_number\":len(limit_dataset)})\n",
        "    return dataset_list\n",
        "\n",
        "\n",
        "#get only 10\n",
        "all_legitimate_dataset_10 = get_dataset_from_files(label=0, limit=10); \n",
        "all_phishing_dataset_10 = get_dataset_from_files(label=1, limit=10)\n",
        "\n",
        "all_legitimate_dataset= get_dataset_from_files(label=0); \n",
        "all_phishing_dataset = get_dataset_from_files(label=1); \n",
        "\n",
        "# print(f\"10_legitimate_dataset => {all_legitimate_dataset_10}\")\n",
        "# print(f\"10_phishing_dataset=> {all_phishing_dataset_10}\")\n",
        "\n",
        "# print(f\"all_legitimate_dataset => {all_legitimate_dataset}\")\n",
        "# print(f\"all_phishing_dataset=> {all_phishing_dataset}\")\n",
        "print(f\"all_email => {get_dataset_from_files()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# only get legit email dataset that are not empty\n",
        "def get_all_legit_email_dataset():\n",
        "    all_legit_email_data = []\n",
        "    for legit in all_phishing_dataset_10:\n",
        "        data = legit['data']\n",
        "        #print(data)\n",
        "        if data.num_rows > 0:\n",
        "            #rint(f\"onlylegit=>{legit['data']}\")\n",
        "            all_legit_email_data.append(data)\n",
        "    return all_legit_email_data\n",
        "\n",
        "# only get phishing email dataset that are not empty\n",
        "def get_all_phishing_email_dataset():\n",
        "    all_phishing_email_data = []\n",
        "    for phishing in all_phishing_dataset_10: \n",
        "        data = phishing['data']\n",
        "        #print(data)\n",
        "        if data.num_rows > 0:\n",
        "           #print(f\"onlyphishing=>{phishing['data']}\")\n",
        "            all_phishing_email_data.append(data)\n",
        "    return all_phishing_email_data\n",
        "# all email dataet\n",
        "def get_all_email_dataset_object():\n",
        "    all_legit_email_data = []\n",
        "    for legit in get_dataset_from_files():\n",
        "        data = legit['data']\n",
        "        #print(data)\n",
        "        if data.num_rows > 0:\n",
        "            #rint(f\"onlylegit=>{legit['data']}\")\n",
        "            all_legit_email_data.append(data)\n",
        "    return all_legit_email_data\n",
        "    \n",
        "# print(f\"get_all_legit_email_dataset => {get_all_legit_email_dataset()}\")\n",
        "# print(f\"get_all_phishing_email_dataset => {get_all_phishing_email_dataset()}\")\n",
        "# print(f\"get_all_email_dataset_object => {get_all_email_dataset_object()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets, Dataset\n",
        "from typing import List\n",
        "\n",
        "# All datasets must have the same column names in the same order for concatenate_datasets to work without issues.\n",
        "def combine_datasets(dataset_list: List[Dataset]) -> Dataset:\n",
        "    # Ensure all datasets have the same column order (optional but recommended for consistency)\n",
        "    first_columns = dataset_list[0].column_names\n",
        "    aligned_datasets = [\n",
        "        ds.rename_columns({col: col for col in ds.column_names})  # Force reordering to match\n",
        "        .map(lambda x: x, remove_columns=[col for col in ds.column_names if col not in first_columns])\n",
        "        .cast(dataset_list[0].features)  # Align feature types if needed\n",
        "        if ds.column_names != first_columns else ds\n",
        "        for ds in dataset_list\n",
        "    ]\n",
        "\n",
        "    combined_dataset = concatenate_datasets(aligned_datasets)\n",
        "    return combined_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#combine in a single dataset\n",
        "# combined_legit_email_dataset = combine_datasets(get_all_legit_email_dataset()).select(range(100))\n",
        "# combined_phishing_email_dataset = combine_datasets(get_all_phishing_email_dataset()).select(range(100))\n",
        "combined_legit_email_dataset = combine_datasets(get_all_legit_email_dataset())\n",
        "combined_phishing_email_dataset = combine_datasets(get_all_phishing_email_dataset())\n",
        "all_emails_dataset_only = combine_datasets(get_all_email_dataset_object())\n",
        "\n",
        "\n",
        "# print(f\"legit_email_dataset=> {combined_legit_email_dataset}\")\n",
        "# print(f\"phishing_email_dataset=> {combined_phishing_email_dataset}\")\n",
        "# print(f\"all_emails_dataset_only=> {all_emails_dataset_only}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNIhwNJV6vO4"
      },
      "source": [
        "# Some Helpers Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JcqN6EQr4EXH",
        "outputId": "18726646-74ca-4f37-d13e-6c2a86001c9a"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "def extract_email_username(email_string: Optional[str]) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"\n",
        "    Extracts the first email and the associated name (if any) from a string.\n",
        "\n",
        "    Args:\n",
        "        email_string: The input string.\n",
        "\n",
        "    Returns:\n",
        "        A tuple of (email, username). Username may be None if not found.\n",
        "    \"\"\"\n",
        "    if not email_string:\n",
        "        return None, None\n",
        "\n",
        "    # Pattern: Name <email>\n",
        "    match = re.search(r'([\\w\\s\\\"\\'\\-\\.]+)?<?([\\w\\.\\-+]+@[\\w\\.\\-]+\\.\\w+)>?', email_string)\n",
        "    if match:\n",
        "        name = match.group(1)\n",
        "        email = match.group(2)\n",
        "        name = name.strip() if name else None\n",
        "        return email, name\n",
        "\n",
        "    return None, None\n",
        "\n",
        "# #example with legitimate dataset\n",
        "# for data in combined_legit_email_dataset:\n",
        "#   #print(data['sender'])\n",
        "#   email,username = extract_email_username(data['sender'])\n",
        "#   if email and username:\n",
        "#     print(f\"Email: {email}, Username: {username}\")\n",
        "#   elif email:\n",
        "#     print(f\"Email: {email}, Not Username found\")\n",
        "#   else:\n",
        "#     print(data['sender'], \"No email or username found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0CEgnyu5iIU",
        "outputId": "a34ef762-1920-4abd-d6ea-b81fd27ba199"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_url_from_body(message_body: str,is_url:int) -> str | None:\n",
        "  \"\"\"\n",
        "  Extracts a URL from a string only when is_url is true.\n",
        "\n",
        "  Args:\n",
        "    message_body: The input string.\n",
        "\n",
        "  Returns:\n",
        "    The extracted URL, or None if not found.\n",
        "  \"\"\"\n",
        "  if (is_url == 1):\n",
        "      url_match = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', message_body)\n",
        "      if url_match:\n",
        "          return url_match.group(0)\n",
        "  return None\n",
        "\n",
        "# #example with legitimate dataset\n",
        "# for data in combined_legit_email_dataset:\n",
        "#   url = extract_url_from_body(data['body'],data['urls'])\n",
        "#   if url:\n",
        "#     print(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LrSkyt6P94nS",
        "outputId": "2e65bdd1-7a5e-463e-ab95-211daa73364a"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import List # Import List for type hinting\n",
        "\n",
        "def extract_email_from_body(message_body: str) -> List[str]:\n",
        "  \"\"\"\n",
        "  Extracts all unique email addresses from a message body using a comprehensive regex.\n",
        "\n",
        "  Args:\n",
        "    message_body: The input string (message body).\n",
        "\n",
        "  Returns:\n",
        "    A list of unique extracted email addresses. Returns an empty list if none are found.\n",
        "  \"\"\"\n",
        "  # Add a check for None input\n",
        "  if message_body is None:\n",
        "      return []\n",
        "\n",
        "  # More comprehensive regex for email extraction using findall\n",
        "  email_list = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', message_body)\n",
        "\n",
        "  # Remove duplicates by converting to a set and back to a list\n",
        "  unique_emails = list(set(email_list))\n",
        "\n",
        "  return unique_emails\n",
        "\n",
        "\n",
        "# #example with legitimate dataset\n",
        "# for data in combined_legit_email_dataset:\n",
        "#   emails = extract_email_from_body(data['body'])\n",
        "#   if emails:\n",
        "#     print(f\"Unique Emails extracted: {emails}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrV6ELG1DWdu",
        "outputId": "9ef9a154-4985-459d-9e5e-32e056ced192"
      },
      "outputs": [],
      "source": [
        "def is_phishing(label:int)->bool:\n",
        "  if(label == 1):\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "# #example with legitimate dataset\n",
        "# for data in combined_legit_email_dataset:\n",
        "#   is_phishing_email = is_phishing(data['label'])\n",
        "#   print(f\"is_phishing: {is_phishing_email}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pblN9HdlMwNK"
      },
      "source": [
        "Define a structure data for the email database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "glCkdotRD1x5"
      },
      "outputs": [],
      "source": [
        "#define class model\n",
        "from typing import List, Optional, TypedDict\n",
        "from pydantic import BaseModel, Field # Import Field\n",
        "\n",
        "class EmailDataSet(BaseModel):\n",
        "  is_phishing: bool = Field(..., description=\"Boolean indicating if the email is labeled as phishing in the dataset.\")\n",
        "  sender_name: str | None = Field(None, description=\"The name of the email sender, if extracted.\") # Allow sender_name to be None as extract_email_username can return None for name\n",
        "  sender_email: str = Field(..., description=\"The email address of the sender.\") # Made mandatory\n",
        "  receiver_email: str = Field(..., description=\"The email address of the receiver.\") # Made mandatory\n",
        "  date: str = Field(..., description=\"The date the email was sent or received.\") # Made mandatory\n",
        "  subject: str = Field(..., description=\"The subject line of the email.\") # Made mandatory\n",
        "  body: str = Field(..., description=\"The main body content of the email.\") # Made mandatory\n",
        "  urls: List[str] = Field([], description=\"A list of URLs extracted from the email body.\")\n",
        "  extra_emails: List[str] = Field([], description=\"A list of unique email addresses found within the email body.\")\n",
        "\n",
        "\n",
        "class UrlCheckResult(BaseModel):\n",
        "  is_malicious: bool = Field(..., description=\"Boolean indicating if the URL was flagged as malicious by the security checker.\")\n",
        "  url: str = Field(..., description=\"The URL that was checked.\")\n",
        "  confidence: float = Field(..., description=\"Confidence score (0.0 to 1.0) for the maliciousness check.\") # 0.0 to 1.0\n",
        "  details: Optional[str] = Field(None, description=\"Optional details or explanation from the security checker.\") # Explanation from sec-mcp\n",
        "\n",
        "# final output structure from the analysis agent\n",
        "class AnalysisResult(BaseModel):\n",
        "  is_phishing: bool = Field(..., description=\"Boolean indicating if the email is labeled as phishing in the dataset.\")\n",
        "  trust_score: int = Field(..., description=\"Trust score (0 to 100) for the email.\") # 0 to 100\n",
        "  explanation: str = Field(..., description=\"Explanation why it is phishing or not phishing.\")\n",
        "  recommendation: str = Field(..., description=\"Recommendation to the user.\")\n",
        "  urls: List[str] = Field([], description=\"A list of URLs extracted from the email body.\")\n",
        "  url_check_results: List[UrlCheckResult] = Field([], description=\"A list of UrlCheckResult objects for malicious URLs found in the email.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiDLPdw13IgW"
      },
      "source": [
        "format the dataset and return a list of structured email data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4BQHiKVd3ZXY",
        "outputId": "fd943974-5973-43ce-dfe6-2699af207422"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "def format_dataset(dataset: Dataset) -> List[EmailDataSet]:\n",
        "  emails_data: List[EmailDataSet] = [] # Initialize as an empty list\n",
        "  try:\n",
        "      for data in dataset:\n",
        "        urls = []  # Initialize for each email\n",
        "        # emails_in_body = [] # Initialize for each email - This will now be assigned the list directly\n",
        "\n",
        "        # Use .get() with a default value for potentially missing or None fields\n",
        "        # Use \"\" for strings, [] for lists, 0 for integers, False for booleans etc.\n",
        "        sender_val = data.get('sender', '')\n",
        "        sender_email, sender_name = extract_email_username(sender_val) # Pass the potentially default value to the helper\n",
        "\n",
        "        receiver_email_val = data.get(\"receiver\", \"\") # Get value with default\n",
        "        date_received_val = data.get(\"date\", \"\") # Get value with default\n",
        "        subject_val = data.get(\"subject\", \"\") # Get value with default\n",
        "        body_val = data.get(\"body\", \"\") # Get value with default\n",
        "        urls_flag_val = data.get('urls', 0) # Default to 0 for urls flag\n",
        "        label_val = data.get('label', 0) # Default to 0 for label\n",
        "\n",
        "\n",
        "        url_inside_body = extract_url_from_body(body_val, urls_flag_val) # Use the potentially defaulted body_val and urls_flag_val\n",
        "\n",
        "        is_phish = is_phishing(label_val) # Use the potentially defaulted label_val\n",
        "\n",
        "\n",
        "        if url_inside_body:\n",
        "          urls.append(url_inside_body)\n",
        "\n",
        "        # Use the updated extract_email_from_body function\n",
        "        emails_in_body = extract_email_from_body(body_val) # Use the potentially defaulted body_val\n",
        "        # No need to append to emails_in_body here as extract_email_from_body already returns a list\n",
        "\n",
        "        email_data_item = EmailDataSet( # Use a different variable name to avoid confusion\n",
        "          sender_name=sender_name if sender_name is not None else \"\", # Ensure sender_name is string or \"\"\n",
        "          sender_email=sender_email if sender_email is not None else \"\", # Ensure sender_email is string or \"\"\n",
        "          receiver_email=receiver_email_val if receiver_email_val is not None else \"\", # Explicitly check and default\n",
        "          date=date_received_val if date_received_val is not None else \"\", # Explicitly check and default\n",
        "          subject=subject_val if subject_val is not None else \"\", # Explicitly check and default\n",
        "          body=body_val if body_val is not None else \"\", # Explicitly check and default\n",
        "          urls=urls, # urls list will be handled correctly even if body was None\n",
        "          extra_emails=emails_in_body, # Assign the list of unique emails directly, handled by extract_email_from_body's None check\n",
        "          is_phishing=is_phish\n",
        "        )\n",
        "        emails_data.append(email_data_item)\n",
        "\n",
        "      return emails_data\n",
        "  except Exception as e:\n",
        "    error = f\"Error formatting dataset: {e}\"\n",
        "    print(error)\n",
        "    return []\n",
        "\n",
        "\n",
        "# # examples\n",
        "# #example with legitimate dataset\n",
        "# formatted_dataset = format_dataset(combined_legit_email_dataset)\n",
        "# for data in formatted_dataset:\n",
        "#   print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDDNUdKxGXLT"
      },
      "source": [
        "Function to check if urls are malicious"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivbC1bjNNYIL",
        "outputId": "35f65a04-544c-49d1-d9e8-c01dc57ede01"
      },
      "outputs": [],
      "source": [
        "from operator import is_\n",
        "from sec_mcp import SecMCP\n",
        "# initialize SecMCP once\n",
        "sec_mcp_checker = SecMCP()\n",
        "def check_urls_tool(urls: List[str]) -> List[UrlCheckResult]:\n",
        "  \"\"\"check a list of URLs against security blacklist using the sec_mcp\n",
        "    library. Return a list of check results, one for each URL.\n",
        "  \"\"\"\n",
        "  if not urls: # Corrected condition to check if the list is empty\n",
        "    return []\n",
        "\n",
        "  #print(f\"checking {len(urls)} URLs: {urls}\")\n",
        "  results = []\n",
        "  try:\n",
        "    # use batch checking for efficiency\n",
        "    batch_results = sec_mcp_checker.check_batch(urls)\n",
        "    for i, url in enumerate(urls):\n",
        "      #\n",
        "      if i < len(batch_results):\n",
        "        check_result = batch_results[i]\n",
        "        is_malicious = check_result.blacklisted\n",
        "        confidence = 1.0 if is_malicious else 0.5\n",
        "        details = check_result.explanation\n",
        "        results.append({\n",
        "          'url': url,\n",
        "          'is_malicious': is_malicious,\n",
        "          'confidence': confidence,\n",
        "          'details': details\n",
        "        })\n",
        "      else: # Handle potential mismatch in results length (unlikely but safe)\n",
        "          results.append({\n",
        "            'url': url,\n",
        "            'is_malicious': False,\n",
        "            'confidence': 0.0,\n",
        "            'details': \"Check result unavalable\"\n",
        "          })\n",
        "    return results\n",
        "  except Exception as e:\n",
        "    # Return default safe results on error\n",
        "    error_results = [{\n",
        "      'url': url,\n",
        "      'is_malicious': False,\n",
        "      'confidence': 0.0,\n",
        "      'details': f\"Error checking URL: {str(e)}\"\n",
        "    } for url in urls]\n",
        "    print(f\"Error checking URL: {error_results}\")\n",
        "    return error_results\n",
        "\n",
        "# # Example Test:\n",
        "# formatted_dataset = format_dataset(combined_legit_email_dataset)\n",
        "# # Flatten the list of lists of URLs into a single list of URLs\n",
        "# urls_to_check = [url for data in formatted_dataset for url in data.urls]\n",
        "# check_urls_result = check_urls_tool(urls_to_check)\n",
        "# for result in check_urls_result:\n",
        "\n",
        "  print(f\"url_checker => {result}\")\n",
        "# or do this\n",
        "#for data in formatted_dataset:\n",
        " # if data.urls:\n",
        "  #  urls_results = check_malicious_urls(data.urls)\n",
        "   # print(f\"urls results: {urls_results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1sH_2ZNNC_D"
      },
      "source": [
        "create an ai prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKat9y1ZNClS",
        "outputId": "21bd1713-8a7c-4a5b-e83b-3f30c0199e72"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "def get_system_prompt() -> SystemMessage:\n",
        "  system_message = \"\"\"\n",
        "    You are a cybersecurity expert specialized in analyzing emails for phishing attempts.\n",
        "\n",
        "    Your goal is to determine if an email is phishing (is_phishing: true) or legitimate (is_phishing: false) \n",
        "    and provide a confidence score (trusted_score: 0-100, where 0 is highly likely phishing, 100 is highly likely legitimate).\n",
        "\n",
        "    You have access to ONE tool:\n",
        "      - check_urls_tool(url_list: List[str]) - List[UrlCheckResult]: Checks a list of URLs against security blacklists.\n",
        "        Each result indicates if the URL is malicious and provides details.\n",
        "\n",
        "    Analysis Steps:\n",
        "    1. Examine sender address: Does it look authentic? Spoofed? From a suspicious domain?\n",
        "    2. Analyze subject line: Urgency? Generic greetings? Weird characters? Misspellings?\n",
        "    3. Read the body content: Look for urgency/pressure tactics, grammar/spelling errors, requests for sensitive information (credentials, PII), suspicious offers, mismatched links (text vs. actual URL if available).\n",
        "    4. Analyze URLs:\n",
        "      - Identify ALL uRLs present in the email body text\n",
        "      - if URLs are present, **you MUST call `check_urls_tool`** with the complete list of \n",
        "        identified URLs.\n",
        "      - Integrate the `check_urls_tool` results into your analysis. Are any URLs flagged as malicious?\n",
        "        Do the domains look legitimate or are they typosquatting/impersonating known brands? Does the path look suspicious?\n",
        "    5. Synthesize findings: Combine evidence from sender, subject, body, and URL checks. A single indicator might not be conclusive, but multiple red flags increase the likelihood of phishing.\n",
        "    6. Assign Trust Score: Based on the overall evidence, assign a score from 0 (definitely phishing) to 100 (definitely legitimate).\n",
        "\n",
        "  \"\"\"\n",
        "  return SystemMessage(content=system_message)\n",
        "\n",
        "def get_message_template(email_data_set: EmailDataSet ) -> List[HumanMessage]:\n",
        "  # Use f-string for clean formatting\n",
        "  input_email_section = f\"\"\"Analyze the following email:\n",
        "    <input_email>\n",
        "    From: {email_data_set.sender_email}\n",
        "    Subject: {email_data_set.subject}\n",
        "\n",
        "    Body:\n",
        "    -------\n",
        "    {email_data_set.body}\n",
        "    -------\n",
        "\n",
        "    additional_emails: {email_data_set.extra_emails}\n",
        "\n",
        "    URLs Identified in Body: {email_data_set.urls if email_data_set.urls else \"No URLs identified\"}\n",
        "    </input_email>\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  messages = [\n",
        "    HumanMessage(content=input_email_section),\n",
        "  ]\n",
        " \n",
        "  return messages\n",
        "\n",
        "# #example\n",
        "# email_data_set =  format_dataset(combined_legit_email_dataset)\n",
        "# system_message = get_system_prompt()\n",
        "# print(\"==system_message== \")\n",
        "# print(system_message.content)\n",
        "# for result in email_data_set:\n",
        "#   message_template = get_message_template(result)\n",
        "#   print(f\"message_template => {message_template}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LeT3dymzNbQ"
      },
      "source": [
        "use llm to generate the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "def email_analyzer_agent():\n",
        "    try:\n",
        "      llm = get_llm()\n",
        "      system_prompt = get_system_prompt()\n",
        "      agent = create_react_agent(model=llm, tools=[check_urls_tool], name=\"EmailAnalyzerAgent\", prompt=system_prompt.content, response_format=AnalysisResult )\n",
        "      return agent\n",
        "    except Exception as e:\n",
        "      print(f\"Error creating agent: {e}\")\n",
        "      return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9FvkY7i0DAX",
        "outputId": "8c3b7ffd-6ade-481a-bfd6-c050247144ae"
      },
      "outputs": [],
      "source": [
        "# use the llm to generate the training data\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "def run_llm(dataset:List[EmailDataSet])-> List[Dict] | None:\n",
        "  ai_response_data = []\n",
        "  try:\n",
        "    #llm = get_llm()\n",
        "    agent = email_analyzer_agent()\n",
        "    # only loop through 1 email for testing\n",
        "    for data in dataset:\n",
        "      # get prompt template\n",
        "      message_template = get_message_template(data)\n",
        "      #print(f\"Message template: {message_template}\")\n",
        "      response = agent.invoke({\"messages\":message_template})\n",
        "      \n",
        "      real_human_input = message_template[0].content\n",
        "      real_ai_output: AnalysisResult = response['structured_response']\n",
        "      #add to list\n",
        "      ai_response_data.append({\n",
        "          \"email_input\": real_human_input,\n",
        "          \"llm_output\": real_ai_output.model_dump_json(),\n",
        "          \"llm_model\": llm_model\n",
        "      })\n",
        "    return ai_response_data\n",
        "  except Exception as e:\n",
        "    print(f\"Error running agent: {e}\")\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from datetime import datetime\n",
        "import json\n",
        "from typing import TextIO\n",
        "\n",
        "def save_training_data(user_prompt: HumanMessage, actual_label: bool, analysis_result: AnalysisResult, is_correct: bool, file: TextIO) -> None:\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")\n",
        "        json_data = {\n",
        "            \"analysis_timestamp\": timestamp,\n",
        "            \"user_prompt\": user_prompt.content,  \n",
        "            \"output\": analysis_result.model_dump(),\n",
        "            \"llm_model\": llm_model,\n",
        "            \"evaluation\": {\n",
        "                \"actual_label\": actual_label,\n",
        "                \"predicted_label\": analysis_result.is_phishing,\n",
        "                \"is_correct\": is_correct\n",
        "            }\n",
        "        }\n",
        "\n",
        "        json.dump(json_data, file, indent=2)\n",
        "        file.write('\\n')  # Add newline to separate JSONL entries\n",
        "        print(f\"Data appended to file: {file.name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving training data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save training data\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def added_data_to_jsonl(user_prompt : HumanMessage, actual_label: bool, analysis_result: AnalysisResult, is_correct: bool, file_name:str)->str | None:\n",
        "  \"\"\"\n",
        "  Generic function to add data to a JSONL file and return the file path\n",
        "  \"\"\"\n",
        "  try:\n",
        "    full_file_name = f\"{file_name}.jsonl\"\n",
        "    dir_name = \"llm_datasets\"\n",
        "    file_path = os.path.join(dir_name, full_file_name)\n",
        "\n",
        "    #ensure directory exists before opening file\n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "\n",
        "    #Now safely open and append data\n",
        "    with open(file_path, 'a', encoding='utf-8') as file:\n",
        "      save_training_data(user_prompt, actual_label, analysis_result, is_correct, file)\n",
        "    return file_path\n",
        "  except Exception as e:\n",
        "    print(f\"Error writing to JSONL file: {str(e)}\")\n",
        "    return None\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Anti Phishing Email Classifier Workflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional, TypedDict\n",
        "\n",
        "\n",
        "class WorkflowState(TypedDict):\n",
        "    input: EmailDataSet\n",
        "    output: Optional[AnalysisResult] # LLm generated output\n",
        "    is_output_correct: Optional[bool] # valid output.is_phishing with input.is_phishing, when compare to the input_decision\n",
        "    llm_dataset_path: Optional[str]\n",
        "    error: Optional[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Nodes\n",
        "# node for analyze legitimate emaildata set\n",
        "def analyze_email_dataset(state: WorkflowState)-> dict:\n",
        "    try:\n",
        "        input = state.get(\"input\")\n",
        "        agent = email_analyzer_agent()\n",
        "        # get prompt template\n",
        "        message_template = get_message_template(input)\n",
        "        #print(f\"Message template: {message_template}\")\n",
        "        response = agent.invoke({\"messages\":message_template})\n",
        "        ai_response =  response['structured_response']\n",
        "        return {\"output\": ai_response, \"error\": None}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analyze_legitimate node: {e}\")\n",
        "        err_result = AnalysisResult(\n",
        "                    is_phishing=False, \n",
        "                    trust_score=0, \n",
        "                    explaination=f\"[Analysis Error: Agent execution failed: {str(e)}]\",\n",
        "                    recommendation = \"Proceed with extreme caution.\",\n",
        "                    urls = [],\n",
        "                    url_check_result = []\n",
        "                )\n",
        "                    \n",
        "        return {\"output\": err_result, \"error\": str(e)}\n",
        "# node to validate output\n",
        "def validate_output(state: WorkflowState)-> dict:\n",
        "    try:\n",
        "        input = state.get(\"input\")\n",
        "        output = state.get(\"output\")\n",
        "        err = state.get(\"error\")\n",
        "        if err is None:\n",
        "            output_is_phishing = output.is_phishing\n",
        "            input_is_phishing = input.is_phishing\n",
        "            is_valid = output_is_phishing == input_is_phishing\n",
        "            return {\"is_output_correct\": is_valid, \"error\": None}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in validate_output node: {e}\")\n",
        "        return {\"is_output_correct\": False, \"error\": str(e)}\n",
        "\n",
        "# node for training data set\n",
        "def store_output_data(state: WorkflowState)-> dict:\n",
        "    try:\n",
        "        input = state.get(\"input\")\n",
        "        analysis_result = state.get(\"output\")\n",
        "        is_output_correct = state.get(\"is_output_correct\")\n",
        "        user_prompt = get_message_template(input)\n",
        "\n",
        "        if is_output_correct:\n",
        "            #store the output in a file\n",
        "            is_added = added_data_to_jsonl(user_prompt[0],input.is_phishing,analysis_result,is_output_correct,f\"valid_training_data\")\n",
        "            if is_added is not None:\n",
        "                return {\"llm_dataset_path\": is_added, \"error\": None}\n",
        "            else:\n",
        "                return {\"llm_dataset_path\": None, \"error\": \"Failed to add valid data to JSONL file\"}\n",
        "        else:\n",
        "            is_added = added_data_to_jsonl(user_prompt[0],input.is_phishing,analysis_result,is_output_correct,f\"invalid_training_data\")\n",
        "            if is_added is not None:\n",
        "                return {\"llm_dataset_path\": is_added, \"error\": None}\n",
        "            else:\n",
        "                return {\"llm_dataset_path\": None, \"error\": \"Failed to add invaliddata to JSONL file\"}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in store_correct_output node: {e}\")\n",
        "        return {\"llm_dataset_path\": None, \"error\": str(e)}\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangGraph workflow created successfully\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x0000012B8CFE5760>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create the workfow state machine\n",
        "\n",
        "from langgraph.graph.state import StateGraph, END, CompiledStateGraph\n",
        "\n",
        "def create_workflow()-> CompiledStateGraph:\n",
        "    try:\n",
        "        workflow = StateGraph(WorkflowState)\n",
        "        # Add nodes to the graph\n",
        "        workflow.add_node(\"analyze email\", analyze_email_dataset)\n",
        "        workflow.add_node(\"validate_output\", validate_output)\n",
        "        workflow.add_node(\"report_output\", store_output_data)\n",
        "\n",
        "        # Define the flow of execution\n",
        "        workflow.set_entry_point(\"analyze email\")\n",
        "        workflow.add_edge(\"analyze email\", \"validate_output\")\n",
        "        workflow.add_edge(\"validate_output\", \"report_output\")\n",
        "        workflow.add_edge(\"report_output\", END)\n",
        "\n",
        "        email_analyzer_app = workflow.compile()\n",
        "        print(\"LangGraph workflow created successfully\")\n",
        "        return email_analyzer_app\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating workflow: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None \n",
        "#test\n",
        "create_workflow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-SydkdHq7ak"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any\n",
        "from datasets import Dataset\n",
        "def run_anti_phishing_email_classifier_workflow(dataset: Dataset)->List[Dict[str, Any]]:\n",
        "    try:\n",
        "        email_dataset = format_dataset(dataset)\n",
        "        workflow =  create_workflow()\n",
        "        results = []\n",
        "        for data in email_dataset:\n",
        "            # initialize the workflow state\n",
        "            init_state = WorkflowState(\n",
        "                # the input.is_phishing is filtered out during prompting\n",
        "                input=data,\n",
        "                output=None,\n",
        "                is_output_correct=False,\n",
        "                llm_dataset_path=None,\n",
        "                error=None\n",
        "            )\n",
        "            # run the workflow\n",
        "            final_state = workflow.invoke(init_state)\n",
        "            err = final_state.get(\"error\")\n",
        "            if err:\n",
        "                result =  {\n",
        "                    \"status\": \"error\",\n",
        "                    \"message\": err,\n",
        "                    \"subject\": data.subject,\n",
        "                    \"analysis_result\": final_state.get(\"output\"),\n",
        "                    \"is_correct\": final_state.get(\"is_output_correct\"),\n",
        "                    \"actual_label\": data.is_phishing,\n",
        "                    \"llm_dataset_files\": final_state.get(\"llm_dataset_path\"),\n",
        "                }\n",
        "            else:\n",
        "                if not final_state.get(\"output\"):\n",
        "                    result = {\n",
        "                        \"status\": \"error\",\n",
        "                        \"message\": \"No analysis result found\",\n",
        "                        \"subject\": data.subject,\n",
        "                        \"analysis_result\": None,\n",
        "                        \"is_correct\": final_state.get(\"is_output_correct\"),\n",
        "                        \"actual_label\": data.is_phishing,\n",
        "                        \"llm_dataset_files\": final_state.get(\"llm_dataset_path\"),\n",
        "                    }\n",
        "                else:\n",
        "                    result = {\n",
        "                        \"status\": \"success\",\n",
        "                        \"message\": \"Analysis completed successfully\",\n",
        "                        \"subject\": data.subject,\n",
        "                        \"analysis_result\": final_state.get(\"output\"),\n",
        "                        \"is_correct\": final_state.get(\"is_output_correct\"),\n",
        "                        \"actual_label\": data.is_phishing,\n",
        "                        \"llm_dataset_files\": final_state.get(\"llm_dataset_path\"),\n",
        "                    }\n",
        "            results.append(result)\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        err_msg = f\"Critical error during email analysis pipeline: {str(e)}\"\n",
        "        print(f\"[Pipeline Error] {err_msg}\")\n",
        "        traceback.print_exc()\n",
        "        return []\n",
        "        \n",
        "   \n",
        "        \n",
        "            \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangGraph workflow created successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-24 23:21:30,640 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:21:31,367 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:21:38,485 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data appended to file: llm_datasets\\valid_training_data.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-24 23:21:43,212 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:21:43,762 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:21:51,448 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data appended to file: llm_datasets\\valid_training_data.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-24 23:22:01,458 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:22:06,662 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:22:22,901 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data appended to file: llm_datasets\\valid_training_data.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-24 23:22:42,158 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:22:56,155 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in store_correct_output node: added_data_to_jsonl() missing 1 required positional argument: 'file_name'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-24 23:23:03,065 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:23:04,674 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
            "2025-07-24 23:23:16,837 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in store_correct_output node: added_data_to_jsonl() missing 1 required positional argument: 'file_name'\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32db90b95cdf4232aacb7d3fbc3d3b21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analysis failed for email 3: added_data_to_jsonl() missing 1 required positional argument: 'file_name'\n",
            "Analysis failed for email 4: added_data_to_jsonl() missing 1 required positional argument: 'file_name'\n",
            "\n",
            "--- Evaluation Results ---\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n",
            "\n",
            "Confusion Matrix:\n",
            "True Negatives (correctly identified legitimate): 0\n",
            "False Positives (legitimate misclassified as phishing): 0\n",
            "False Negatives (phishing misclassified as legitimate): 0\n",
            "True Positives (correctly identified phishing): 0\n",
            "\n",
            "Summary saved to evaluation_summary_20250724_232318.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\developer\\montimage\\anti_phishing_email_classifier_workflow\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>actual_label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>trust_score</th>\n",
              "      <th>is_correct</th>\n",
              "      <th>llm_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Never agree to be a loser</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>llama3.2:3b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Befriend Jenna Jameson</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>llama3.2:3b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN.com Daily Top 10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>llama3.2:3b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     subject  actual_label  predicted_label  trust_score  \\\n",
              "0  Never agree to be a loser             1                1           20   \n",
              "1     Befriend Jenna Jameson             1                1           20   \n",
              "2       CNN.com Daily Top 10             1                1           20   \n",
              "\n",
              "   is_correct    llm_model  \n",
              "0        True  llama3.2:3b  \n",
              "1        True  llama3.2:3b  \n",
              "2        True  llama3.2:3b  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix   \n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "#Test and display the analysis on a table with limited dataset\n",
        "def test_anti_phishing_email_classifier_workflow():\n",
        "    # Tracking the evaluation metrics\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    results = []\n",
        "    try:\n",
        "        limited_dataset = all_emails_dataset_only.select(range(5))\n",
        "        analysis_results = run_anti_phishing_email_classifier_workflow(limited_dataset)\n",
        "        # Extract predicted label from analysis result\n",
        "        for i, analysis_result in  enumerate(tqdm(analysis_results)):\n",
        "\n",
        "            if isinstance(analysis_result, dict) and analysis_result.get('status') == \"success\" and 'analysis_result' in analysis_result:\n",
        "                analysis_result_object = analysis_result['analysis_result']\n",
        "                predicted_label = 1 if analysis_result_object.is_phishing else 0\n",
        "                trust_score = analysis_result_object.trust_score\n",
        "                # is prediction correct\n",
        "                is_correct = analysis_result.get('is_correct')\n",
        "                actual_label = 1 if analysis_result.get('actual_label', False) else 0\n",
        "\n",
        "                # store metrics for calculation\n",
        "                true_labels.append(actual_label)\n",
        "                predicted_labels.append(predicted_label)\n",
        "                results.append({\n",
        "                    'index': i,\n",
        "                    'actual_label': actual_label,\n",
        "                    'subject': analysis_result.get('subject'),\n",
        "                    'predicted_label': predicted_label,\n",
        "                    'trust_score': trust_score,\n",
        "                    'is_correct': is_correct,\n",
        "                    'llm_dataset_files':analysis_result.get('llm_dataset_files'),\n",
        "                    'llm_model': llm_model\n",
        "                })\n",
        "            else:\n",
        "                print(f\"Analysis failed for email {i}: {analysis_result.get('message','Unknown error')}\")\n",
        "            \n",
        "        \n",
        "            # Calculate evaluation metrics\n",
        "        if true_labels and predicted_labels:\n",
        "            accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "            precision = precision_score(true_labels, predicted_labels, zero_division=0)\n",
        "            recall = recall_score(true_labels, predicted_labels, zero_division=0)\n",
        "            f1 = f1_score(true_labels, predicted_labels, zero_division=0)\n",
        "            conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "            # Unpack confusion matrix into more interpretable variables\n",
        "            if len(conf_matrix) == 2 and len(conf_matrix[0]) == 2:\n",
        "                tn, fp = conf_matrix[0]\n",
        "                fn, tp = conf_matrix[1]\n",
        "            else:\n",
        "                tn = fp = fn = tp = 0\n",
        "\n",
        "            # Create a results DataFrame for visualization\n",
        "            results_df = pd.DataFrame(results)\n",
        "\n",
        "            # Visualization of results\n",
        "            print(\"\\n--- Evaluation Results ---\")\n",
        "            print(f\"Accuracy: {accuracy:.2f}\")\n",
        "            print(f\"Precision: {precision:.2f}\")  # How many predicted phishing emails were actually phishing\n",
        "            print(f\"Recall: {recall:.2f}\")  # How many actual phishing emails were detected\n",
        "            print(f\"F1 Score: {f1:.2f}\")  # Harmonic mean of precision and recall\n",
        "\n",
        "            print(\"\\nConfusion Matrix:\")\n",
        "            print(f\"True Negatives (correctly identified legitimate): {tn}\")\n",
        "            print(f\"False Positives (legitimate misclassified as phishing): {fp}\")\n",
        "            print(f\"False Negatives (phishing misclassified as legitimate): {fn}\")\n",
        "            print(f\"True Positives (correctly identified phishing): {tp}\")\n",
        "\n",
        "            # Save summary to file\n",
        "            summary = {\n",
        "                'metrics': {\n",
        "                    'accuracy': float(accuracy),\n",
        "                    'precision': float(precision),\n",
        "                    'recall': float(recall),\n",
        "                    'f1': float(f1)\n",
        "                },\n",
        "                'confusion_matrix': {\n",
        "                    'tn': int(tn),\n",
        "                    'fp': int(fp),\n",
        "                    'fn': int(fn),\n",
        "                    'tp': int(tp)\n",
        "                },\n",
        "                'results': results\n",
        "            }\n",
        "\n",
        "            # Save summary to JSON file\n",
        "            from datetime import datetime\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            summary_filename = f\"evaluation_summary_{timestamp}.json\"\n",
        "            with open(summary_filename, 'w') as f:\n",
        "                json.dump(summary, f, indent=2, default=str)\n",
        "            print(f\"\\nSummary saved to {summary_filename}\")\n",
        "\n",
        "            # Display results table\n",
        "            display(results_df[['subject', 'actual_label',  'predicted_label', 'trust_score', 'is_correct', 'llm_model']])\n",
        "        else:\n",
        "            print(\"No valid analysis results to evaluate\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in test_anti_phishing_email_classifier_workflow: {e}\")\n",
        "\n",
        "#run\n",
        "test_anti_phishing_email_classifier_workflow()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM/2GliF2Tw4PhB2uTsttn2",
      "include_colab_link": true,
      "mount_file_id": "13oghrH7RAtCYLHZ1t5lPwIHd04zx5h_j",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c1ca73f4234ef2930f46988ac489e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121ef0adc4944fdcb4cbc4958fa37a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a2d0c30f81481097771dc46b5b7588",
            "placeholder": "​",
            "style": "IPY_MODEL_ee28a8c6f7ae4cee9b5b5530b53f0e97",
            "value": "Generating train split: "
          }
        },
        "212bf92465314d8599a2c17b974f24ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "67a2d0c30f81481097771dc46b5b7588": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6814cc14c1f44d7eb26ff232559074ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e4a9c13386409ab38423878af4698a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dad3fe94f6fc4f18936231d99fb860a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6814cc14c1f44d7eb26ff232559074ec",
            "placeholder": "​",
            "style": "IPY_MODEL_f5d91e0958da45ecac4f009fe6a24170",
            "value": " 3332/0 [00:01&lt;00:00, 3074.43 examples/s]"
          }
        },
        "ee28a8c6f7ae4cee9b5b5530b53f0e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f490a84258294dc4b78a7f9997b9ae85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_121ef0adc4944fdcb4cbc4958fa37a74",
              "IPY_MODEL_f9b36947e87e419b80403e8586597fd1",
              "IPY_MODEL_dad3fe94f6fc4f18936231d99fb860a9"
            ],
            "layout": "IPY_MODEL_00c1ca73f4234ef2930f46988ac489e7"
          }
        },
        "f5d91e0958da45ecac4f009fe6a24170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9b36947e87e419b80403e8586597fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212bf92465314d8599a2c17b974f24ee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71e4a9c13386409ab38423878af4698a",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
